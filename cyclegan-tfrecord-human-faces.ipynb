{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-18T18:14:06.255942Z",
     "iopub.status.busy": "2021-01-18T18:14:06.252658Z",
     "iopub.status.idle": "2021-01-18T18:14:14.781483Z",
     "shell.execute_reply": "2021-01-18T18:14:14.779867Z"
    },
    "papermill": {
     "duration": 8.542057,
     "end_time": "2021-01-18T18:14:14.781667",
     "exception": false,
     "start_time": "2021-01-18T18:14:06.239610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re, math, os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008491,
     "end_time": "2021-01-18T18:14:14.799644",
     "exception": false,
     "start_time": "2021-01-18T18:14:14.791153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Notes\n",
    "\n",
    "The following notebook is used to create TFrecords of the Flickr Faces Dataset. I want to do this so that I can train a CycleGAN on TPU's with real faces and fake faces.\n",
    "\n",
    "Check out the main model notebook here -> [Cycle GAN](https://www.kaggle.com/brendanartley/cyclegan-kaokore-model)\n",
    "\n",
    "\n",
    "--\n",
    "\n",
    "NOTE: I ended up leaving out about 15% of the data because the notebook output was too large for the Kaggle environment. We still get over 50,000 high quality images!\n",
    "\n",
    "--\n",
    "\n",
    "Datasets:\n",
    "\n",
    "- [Arnaud58's Flickr Faces Data](https://www.kaggle.com/arnaud58/flickrfaceshq-dataset-ffhq) - 52,000 png images of faces scraped from Flickr with size 512x512\n",
    "\n",
    "- [Kaokore Dataset](https://github.com/rois-codh/kaokore) - 8,000 faces from japanese paintings in the 16th century with size 256x256\n",
    "\n",
    "-- \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-18T18:14:14.821565Z",
     "iopub.status.busy": "2021-01-18T18:14:14.820718Z",
     "iopub.status.idle": "2021-01-18T18:14:14.827498Z",
     "shell.execute_reply": "2021-01-18T18:14:14.828068Z"
    },
    "papermill": {
     "duration": 0.019933,
     "end_time": "2021-01-18T18:14:14.828269",
     "exception": false,
     "start_time": "2021-01-18T18:14:14.808336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#setting seeds for reproducability\n",
    "SEED = 3141\n",
    "\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(SEED) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008603,
     "end_time": "2021-01-18T18:14:14.845933",
     "exception": false,
     "start_time": "2021-01-18T18:14:14.837330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### TFrecord Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T18:14:14.869379Z",
     "iopub.status.busy": "2021-01-18T18:14:14.868318Z",
     "iopub.status.idle": "2021-01-18T18:14:14.878559Z",
     "shell.execute_reply": "2021-01-18T18:14:14.877761Z"
    },
    "papermill": {
     "duration": 0.02332,
     "end_time": "2021-01-18T18:14:14.878698",
     "exception": false,
     "start_time": "2021-01-18T18:14:14.855378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    #Returns a bytes_list from a string / byte.\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    #Returns a float_list from a float / double.\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    #Returns an int64_list from a bool / enum / int / uint.\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T18:14:14.905377Z",
     "iopub.status.busy": "2021-01-18T18:14:14.904584Z",
     "iopub.status.idle": "2021-01-18T18:14:14.908330Z",
     "shell.execute_reply": "2021-01-18T18:14:14.907563Z"
    },
    "papermill": {
     "duration": 0.02058,
     "end_time": "2021-01-18T18:14:14.908501",
     "exception": false,
     "start_time": "2021-01-18T18:14:14.887921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def serialize_example(image, image_name):\n",
    "    feature = {\n",
    "      'image': _bytes_feature(image),\n",
    "      'image_id': _bytes_feature(image_name),\n",
    "      }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008772,
     "end_time": "2021-01-18T18:14:14.926499",
     "exception": false,
     "start_time": "2021-01-18T18:14:14.917727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Flickr Faces TFrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T18:14:14.953874Z",
     "iopub.status.busy": "2021-01-18T18:14:14.952981Z",
     "iopub.status.idle": "2021-01-18T18:14:15.653832Z",
     "shell.execute_reply": "2021-01-18T18:14:15.654650Z"
    },
    "papermill": {
     "duration": 0.718986,
     "end_time": "2021-01-18T18:14:15.654958",
     "exception": false,
     "start_time": "2021-01-18T18:14:14.935972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 52001\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 512\n",
    "N_FILES = 30 #number of TFrecords created\n",
    "HEIGHT, WIDTH = (512, 512)\n",
    "IMG_QUALITY = 100\n",
    "PATH = '../input/flickrfaceshq-dataset-ffhq'\n",
    "PATH_TO_IMG = '../input/flickrfaceshq-dataset-ffhq/'\n",
    "\n",
    "IMGS = os.listdir(PATH)\n",
    "print(\"Number of Images: {}\".format(len(IMGS)))\n",
    "\n",
    "#creating data_frame with image names\n",
    "IMGS.sort()\n",
    "train_df = pd.DataFrame({'image_id': IMGS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T18:14:15.680183Z",
     "iopub.status.busy": "2021-01-18T18:14:15.679225Z",
     "iopub.status.idle": "2021-01-18T18:14:15.699303Z",
     "shell.execute_reply": "2021-01-18T18:14:15.698472Z"
    },
    "papermill": {
     "duration": 0.033372,
     "end_time": "2021-01-18T18:14:15.699518",
     "exception": false,
     "start_time": "2021-01-18T18:14:15.666146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dropping 15% of the image data\n",
    "train_df.drop(train_df.tail(round(len(train_df)*.15)).index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T18:14:15.732708Z",
     "iopub.status.busy": "2021-01-18T18:14:15.731861Z",
     "iopub.status.idle": "2021-01-18T18:14:15.781897Z",
     "shell.execute_reply": "2021-01-18T18:14:15.781115Z"
    },
    "papermill": {
     "duration": 0.072428,
     "end_time": "2021-01-18T18:14:15.782042",
     "exception": false,
     "start_time": "2021-01-18T18:14:15.709614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 1 has 1474 samples\n",
      "File: 2 has 1474 samples\n",
      "File: 3 has 1474 samples\n",
      "File: 4 has 1474 samples\n",
      "File: 5 has 1474 samples\n",
      "File: 6 has 1474 samples\n",
      "File: 7 has 1474 samples\n",
      "File: 8 has 1474 samples\n",
      "File: 9 has 1474 samples\n",
      "File: 10 has 1474 samples\n",
      "File: 11 has 1474 samples\n",
      "File: 12 has 1473 samples\n",
      "File: 13 has 1473 samples\n",
      "File: 14 has 1473 samples\n",
      "File: 15 has 1473 samples\n",
      "File: 16 has 1473 samples\n",
      "File: 17 has 1473 samples\n",
      "File: 18 has 1473 samples\n",
      "File: 19 has 1473 samples\n",
      "File: 20 has 1473 samples\n",
      "File: 21 has 1473 samples\n",
      "File: 22 has 1473 samples\n",
      "File: 23 has 1473 samples\n",
      "File: 24 has 1473 samples\n",
      "File: 25 has 1473 samples\n",
      "File: 26 has 1473 samples\n",
      "File: 27 has 1473 samples\n",
      "File: 28 has 1473 samples\n",
      "File: 29 has 1473 samples\n",
      "File: 30 has 1473 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=N_FILES, shuffle=True, random_state=SEED)\n",
    "train_df['file']=-1\n",
    "\n",
    "for fold_n, (train_idx, val_idx) in enumerate(folds.split(train_df)):\n",
    "    print('File: %s has %s samples' % (fold_n+1, len(val_idx)))\n",
    "    train_df['file'].loc[val_idx] = fold_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011159,
     "end_time": "2021-01-18T18:14:15.803955",
     "exception": false,
     "start_time": "2021-01-18T18:14:15.792796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note: Make sure the PATH_TO_IMG variable has a forward slash at the end of it otherwise it will not be able to find any of the image! \n",
    "\n",
    "EXAMPLE: ../input/flickrfaceshq-dataset-ffhq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-18T18:14:15.838722Z",
     "iopub.status.busy": "2021-01-18T18:14:15.835558Z",
     "iopub.status.idle": "2021-01-18T18:42:38.376179Z",
     "shell.execute_reply": "2021-01-18T18:42:38.375247Z"
    },
    "papermill": {
     "duration": 1702.561364,
     "end_time": "2021-01-18T18:42:38.376306",
     "exception": false,
     "start_time": "2021-01-18T18:14:15.814942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing TFRecord 0 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 1 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 2 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 3 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 4 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 5 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 6 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 7 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 8 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 9 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 10 of 30...\n",
      "1474 samples\n",
      "\n",
      "Writing TFRecord 11 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 12 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 13 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 14 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 15 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 16 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 17 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 18 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 19 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 20 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 21 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 22 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 23 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 24 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 25 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 26 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 27 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 28 of 30...\n",
      "1473 samples\n",
      "\n",
      "Writing TFRecord 29 of 30...\n",
      "1473 samples\n"
     ]
    }
   ],
   "source": [
    "for tfrec_num in range(N_FILES):\n",
    "    print('\\nWriting TFRecord %i of %i...'%(tfrec_num, N_FILES))\n",
    "    samples = train_df[train_df['file'] == tfrec_num]\n",
    "    n_samples = len(samples)\n",
    "    print(f'{n_samples} samples')\n",
    "    with tf.io.TFRecordWriter('FlickrFaces%.2i-%i.tfrec'%(tfrec_num, n_samples)) as writer:\n",
    "        for row in samples.itertuples():\n",
    "            image_name = row.image_id\n",
    "            img_path = f'{PATH_TO_IMG}{image_name}'\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (HEIGHT, WIDTH))\n",
    "                img = cv2.imencode('.png', img, (cv2.IMWRITE_JPEG_QUALITY, IMG_QUALITY))[1].tostring()\n",
    "            except:\n",
    "                print('Error: {} not added'.format(image_name))\n",
    "                continue\n",
    "            \n",
    "            example = serialize_example(img, str.encode(image_name))\n",
    "            writer.write(example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1717.484955,
   "end_time": "2021-01-18T18:42:38.503940",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-18T18:14:01.018985",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
